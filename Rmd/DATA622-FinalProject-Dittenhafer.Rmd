---
title: "Emotion Recognition Neural Network"
author: "Daniel Dittenhafer"
date: "December 13, 2016"
output:
  pdf_document:
    number_sections: yes
  html_document: default
geometry: margin=0.75in
subtitle: 'Final Project Paper for DATA622: Machine Learning & Big Data'
documentclass: article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE, message=FALSE}
library(knitr)
library(knitcitations)
library(RefManageR)

cleanbib()

cite_options(style="markdown")

msEmotionApi <- bibentry(bibtype="Misc",
                         author=person(family="Microsoft Corporation"),
                         publisher="Microsoft Corporation",
                         title="Emotion API",
                         year=2016,
                         month="December",
                         url="https://www.microsoft.com/cognitive-services/en-us/emotion-api")

labeledFaces <- bibentry(bibtype="TechReport",
                         author=personList(person(family="Huang", first="Gary"),
                                           person(family="Ramesh", first="Manu "),
                                           person(family="Berg", first="Tamara"),
                                           person(family="Learned-Miller", first="Erik")),
                         institution ="University of Massachusetts, Amherst",
                         title="Labeled Faces in the Wild: A Database for Studying 
                  Face Recognition in Unconstrained Environments",
                         year=2007,
                         month="October",
                         url="http://vis-www.cs.umass.edu/lfw/")
  
transformImg <- bibentry(bibtype="Misc",
                         author=person(family="Joshi", first="Prateek"),
                         publisher="Packt Publishing Limited",
                         title="OpenCV with Python By Example",
                         year=2015,
                         month="September",
                         url="https://www.packtpub.com/mapt/book/application-development/9781785283932/2/ch02lvl1sec23/Embossing")

roweFaceExpress <- bibentry(bibtype="Misc",
                         author=person(family="Rowe", first="Brian"),
                         title="facial_expressions",
                         year=2016,
                         month="December",
                         url="https://github.com/muxspace/facial_expressions")

kaggleDigitModel <- bibentry(bibtype="Misc",
                         author=person(family="Majumdar", first="Somshubra"),
                         title="Deep Convolutional Network using Keras",
                         year=2016,
                         month="April",
                         url="https://www.kaggle.com/somshubramajumdar/digit-recognizer/deep-convolutional-network-using-keras")

tenMisconceptions <- bibentry(bibtype="Misc",
                         author=person(family="Reid", first="Stuart"),
                         title="10 misconceptions about Neural Networks",
                         year=2014,
                         month="May",
                         url="http://www.turingfinance.com/misconceptions-about-neural-networks/#algo")
  
goodfellowDeepLrn <- bibentry(bibtype="Misc",
                         author=personList(person(family="Goodfellow", first="Ian"),
                                           person(family="Bengio", first="Yoshua"),
                                           person(family="Courville", first="Aaron")),
                         title="Deep Learning",
                         year=2016,
                         month="September",
                         url="http://deeplearningbook.org")
   
```

Submit your final project, which includes the source code of your best model, plus a short (3-4 page) paper summarizing your work. Provide:

* an overview of the problem;
* why it's challenging;
* what techniques you used;
* comparison of performance;
* generalizable lessons learned/takeaways.


# Overview

As part of the course requirements for Machine Learning & Big Data (DATA622), the problem of developing a machine learning model capable of classifying human face images into various emotions was presented. Specifically, the goal was to design and train a neural network to recognize the following 8 emotions and emit a probability of each of the emotion classes given the input 2 dimensional (2D) image. 

1. anger
2. contempt
3. disgust
4. fear
5. happiness
6. neutral
7. sadness
8. surprise

Although this problem is not new to machine learning and solutions already exist `r citep(msEmotionApi)`, the complexities of the mathematics alone are challenging. This, combined with the application of a variety of neural network techniques, make for many unique solutions. Much of the academic theory for the neural network was derived from the text by Ian Goodfellow, et al, ___Deep Learning___ `r citep(goodfellowDeepLrn)`.

# Techniques

The DATA622 class as a whole, under Professor Rowe's guidance, agreed to a general approach using the _Labeled Faces in the Wild_ face database as a basis for training data `r citep(labeledFaces)`. We then labeled each of the included images using the Microsoft Emotion API. This was considered the "gold standard" for our training purposes and shared amongst the class as well as publicly in the [facial_expressions repository on GitHub](https://github.com/muxspace/facial_expressions) `r citep(roweFaceExpress)`.

In order to increase the size of our training and test data sets as well as apply regularization via data, each member of the class created ten image transformations using a variety of APIs and shared the transformations with the class as options for each of us when augmenting our data sets. The following code shows an example of a transformation applied during training `r citep(transformImg)`:

```{python, eval=FALSE}
def cvBlurMotion1(img):
    
    size = 15
    kernel_motion_blur = np.zeros((size, size))
    kernel_motion_blur[int((size - 1) / 2), :] = np.ones(size)
    kernel_motion_blur = kernel_motion_blur / size

    img2 = cv2.filter2D(img, -1, kernel_motion_blur)
    return img2
```

The function, above, along with all code developed as part of this project can be found in the [emotional-faces repository on GitHub](https://github.com/dwdii/emotional-faces).

The initial model was based on a model shared on Kaggle as part of the digit recognition competition `r citep(kaggleDigitModel)`. In general, it used 3 convolutional layers plus 2 dense layers with rectified linear unit activation and a softmax final activation for the class probablities. This initial model was adjusted in minor ways, with followup training and validation to measure performance.

The final model was very similar to the initial model in many ways. It still relied on convolutional layers at the input and hidden layers with 2 dense layers on the end, but had a forth convolutional hidden layer internally. 

```{python, eval=FALSE}
def emotion_model_jh_v5(outputClasses, input_shape=(3, 150, 150), verbose=False):
    model = Sequential()
    model.add(Convolution2D(32, 8, 8, input_shape=input_shape))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Convolution2D(32, 5, 5))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Convolution2D(64, 3, 3))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    model.add(Convolution2D(64, 2, 2))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))    

    model.add(Flatten())
    model.add(Dense(64))
    model.add(Activation('relu'))
    #model.add(Dropout(0.4))
    model.add(Dense(outputClasses))
    model.add(Activation('softmax'))
    
    if verbose:
        print (model.summary())

    model.compile(loss='binary_crossentropy',
                  optimizer='rmsprop',
                  metrics=['accuracy'])

    return model
```

As you can see, the structure is approaching "deep" with the 4 hidden layers. Importantly, the convolutional window begins larger (8x8) on the 150x150 image, and gradually narrows through the remaining 3 convolutional layers. Binary cross entropy was used for the loss function, and Root Mean Square Propagation (RMSProp) was used for the optimization. RMSProp was used for its ability to consistently descend toward the minimum though admittedly not the fastest to arrive `r citep(tenMisconceptions)`. Kind of a tortise approach in a tortise vs hare annalogy.  

Convolutional 2D, hyper params

Max Pooling

Drop out

optimization function

# Performance

TBD

# Conclusions

TBD


# References

```{r, results='asis', echo=FALSE}
BibOptions(style="html", bib.style="authortitle")
bibliography()
```