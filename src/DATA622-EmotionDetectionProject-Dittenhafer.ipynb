{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import emotion_model\n",
    "import dwdii_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagePath = \"/root/facial_expressions/images\"\n",
    "dataPath = \"/root/facial_expressions/data/legend.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['500_picts_satz.csv', 'legend.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/root/facial_expressions/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emoMetaData = dwdii_transforms.load_training_metadata(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13682"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emoMetaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000: King_Abdullah_II_0001.jpg\n",
      "0.010000: Giuseppe_Gibilisco_0003.jpg\n",
      "0.020000: Don_Lake_0001.jpg\n",
      "0.030000: Jason_Priestley_0001.jpg\n",
      "0.040000: Shaukat_Aziz_0002.jpg\n",
      "0.050000: Jim_Hardin_0001.jpg\n",
      "0.060000: Ana_Palacio_0003.jpg\n",
      "0.070000: Nicolas_Escude_0002.jpg\n",
      "0.080000: Janet_Crawford_0001.jpg\n",
      "0.090000: Jayamadhuri_59.jpg\n",
      "0.090000: Taufik_Hidayat_0001.jpg\n",
      "0.100000: George_W_Bush_0193.jpg\n",
      "0.110000: Andres_Pastrana_0001.jpg\n",
      "0.120000: Owen_Wilson_0002.jpg\n",
      "0.130000: Jackie_Chan_0004.jpg\n",
      "0.140000: Laura_Bush_0003.jpg\n",
      "0.150000: Kate_Hudson_0009.jpg\n",
      "0.160000: Anders_Ebbeson_0001.jpg\n",
      "0.170000: Milton_Berle_0001.jpg\n",
      "0.180000: Rudolph_Giuliani_0005.jpg\n",
      "0.190000: Eugene_Teslovic_0001.jpg\n",
      "0.200000: Jason_Alexander_0002.jpg\n",
      "0.210000: Amber_Tamblyn_0001.jpg\n",
      "0.220000: Yann_Martel_0001.jpg\n",
      "0.230000: Jeannette_Biedermann_0001.jpg\n",
      "0.240000: Heather_Locklear_0001.jpg\n",
      "0.250000: Naji_Sabri_0003.jpg\n",
      "0.260000: George_W_Bush_0059.jpg\n",
      "0.270000: Paradorn_Srichaphan_0005.jpg\n",
      "0.280000: Paul_Wolfowitz_0004.jpg\n",
      "0.290000: Tim_Welsh_0001.jpg\n",
      "0.300000: Tammy_Lynn_Michaels_0002.jpg\n",
      "0.310000: Keanu_Reeves_0007.jpg\n",
      "0.320000: Junichiro_Koizumi_0049.jpg\n",
      "0.330000: Chris_Neil_0001.jpg\n",
      "0.340000: Ghassan_Elashi_0001.jpg\n",
      "0.350000: Tony_Blair_0013.jpg\n",
      "0.360000: Thomas_Franklin_0001.jpg\n",
      "0.370000: Dominique_de_Villepin_0004.jpg\n",
      "0.380000: Neri_Marcore_0002.jpg\n",
      "0.390000: Mahmoud_Abbas_0017.jpg\n",
      "0.400000: Deece_Eckstein_0001.jpg\n",
      "0.410000: Mohammad_Al-Sharief_0001.jpg\n",
      "0.420000: Jayamadhuri_148.jpg\n",
      "0.420000: Lyle_Lovett_0001.jpg\n",
      "0.430000: Robert_Altman_0001.jpg\n",
      "0.440000: Daniel_Pearl_0001.jpg\n",
      "0.450000: Aileen_Riggin_Soule_0001.jpg\n",
      "0.460000: Oleksandr_Moroz_0002.jpg\n",
      "0.470000: George_W_Bush_0408.jpg\n",
      "0.480000: Larry_Coker_0001.jpg\n",
      "0.490000: Javier_Vargas_0001.jpg\n",
      "0.500000: Carrie-Anne_Moss_0002.jpg\n",
      "0.510000: Goldie_Hawn_0005.jpg\n",
      "0.520000: Mike_Weir_0010.jpg\n",
      "0.530000: Michael_Jordan_0004.jpg\n",
      "0.540000: FaridaJalal_57.jpg\n",
      "0.540000: Megawati_Sukarnoputri_0011.jpg\n",
      "0.550000: KatrinaKaif_31.jpg\n",
      "0.550000: Arnold_Schwarzenegger_0028.jpg\n",
      "0.560000: John_Abizaid_0007.jpg\n",
      "0.570000: Arnold_Palmer_0003.jpg\n",
      "0.580000: Chan_Gailey_0003.jpg\n",
      "0.590000: Shia_LaBeouf_0002.jpg\n",
      "0.600000: George_W_Bush_0494.jpg\n",
      "0.610000: Condoleezza_Rice_0008.jpg\n",
      "0.620000: David_Hanson_0001.jpg\n",
      "0.630000: Robert_McKee_0001.jpg\n",
      "0.640000: Kofi_Annan_0016.jpg\n",
      "0.650000: Silvio_Berlusconi_0010.jpg\n",
      "0.660000: Robert_Schuller_0001.jpg\n",
      "0.670000: Gerhard_Schroeder_0103.jpg\n",
      "0.680000: George_W_Bush_0477.jpg\n",
      "0.690000: Sergio_Vieira_De_Mello_0010.jpg\n",
      "0.700000: Jim_Furyk_0001.jpg\n",
      "0.710000: Martha_Bowen_0002.jpg\n",
      "0.720000: Lachlan_Murdoch_0001.jpg\n",
      "0.730000: Mark_Heller_0001.jpg\n",
      "0.740000: Andy_Hebb_0002.jpg\n",
      "0.750000: Paul_Henderson_0001.jpg\n",
      "0.760000: Frank_Solich_0004.jpg\n",
      "0.770000: Jim_Flaherty_0001.jpg\n",
      "0.780000: Jacques_Chirac_0027.jpg\n",
      "0.790000: Art_Hoffmann_0002.jpg\n",
      "0.800000: HrithikRoshan_72.jpg\n",
      "0.800000: Debra_Brown_0002.jpg\n",
      "0.810000: Jack_Osbourne_0001.jpg\n",
      "0.820000: Elton_John_0005.jpg\n",
      "0.830000: Martha_Stewart_0003.jpg\n",
      "0.840000: Carey_Lowell_0001.jpg\n",
      "0.850000: Debra_Messing_0003.jpg\n",
      "0.860000: Phan_Van_Khai_0002.jpg\n",
      "0.870000: Tamara_Brooks_0002.jpg\n",
      "0.880000: Phil_Johnson_0001.jpg\n",
      "0.890000: Tariq_Aziz_0002.jpg\n",
      "0.900000: Emmanuelle_Jagodsinski_0001.jpg\n",
      "0.910000: Tommy_Haas_0004.jpg\n",
      "0.920000: Begum_Khaleda_Zia_0002.jpg\n",
      "0.930000: Elsa_Zylberstein_0001.jpg\n",
      "0.940000: Jayamadhuri_178.jpg\n",
      "0.940000: Fred_Thompson_0003.jpg\n",
      "0.950000: Bart_Freundlich_0001.jpg\n",
      "0.960000: Jerry_Springer_0002.jpg\n",
      "0.970000: Blythe_Danner_0001.jpg\n",
      "0.980000: HrithikRoshan_180.jpg\n",
      "0.980000: Vladimir_Putin_0037.jpg\n",
      "0.990000: Misty_Dawn_Clymer_0001.jpg\n",
      "(2000, 350, 350)\n",
      "(2000, 1)\n"
     ]
    }
   ],
   "source": [
    "maxData = 2000\n",
    "X_data, Y_data = dwdii_transforms.load_data(dataPath, imagePath, maxData = maxData, verboseFreq = 200)\n",
    "print X_data.shape\n",
    "print Y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code segment splits the data into training and test data sets. Currently this is just a standard 80/20 split for training and test respectively. A random.shuffle should be probably be added here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "(1600, 350, 350)\n",
      "(400, 350, 350)\n",
      "(1600, 1)\n",
      "(400, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into Training and Test sets\n",
    "trainNdx = int(maxData * .8)\n",
    "print trainNdx\n",
    "X_train, X_test = np.split(X_data, [trainNdx])\n",
    "Y_train, Y_test = np.split(Y_data, [trainNdx])\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "\n",
    "print Y_train.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "In this section, we will apply transformations to the existing images to increase of training data, as well as add a bit of noise in the hopes of improving the overall training activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model\n",
    "In this section, we define the model. The `emotion_model` module contains the model definition itself. `emotion_model_v1` is a basic convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sadness': 6, 'neutral': 2, 'disgust': 1, 'anger': 0, 'surprise': 4, 'fear': 5, 'happiness': 3}\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Map the emotions to integers for categorization later.\n",
    "emotions = dwdii_transforms.emotionNumerics()\n",
    "print emotions\n",
    "print len(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Model ... \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_1 (ZeroPadding2D)    (None, 1, 352, 352) 0           zeropadding2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)    (None, 32, 350, 350)320         zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)      (None, 32, 175, 175)0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)    (None, 32, 177, 177)0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 64, 175, 175)18496       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)      (None, 64, 87, 87)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 484416)      0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 484416)      0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 128)         62005376    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                    (None, 7)           903         dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 62025095\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Model compiled in 7.66789889336 seconds\n"
     ]
    }
   ],
   "source": [
    "model = emotion_model.emotion_model_v1(len(emotions), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code segment trains the model using the `run_network` helper function. I seem to be hitting a memory issue (my interpretation), when I have batches above a certain threshold. Batches=10 work fine, but batches of 100 are too big. May need to allocate more RAM to the docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 7)\n",
      "(400, 7)\n",
      "Training model...\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "testX = X_test.reshape(X_test.shape[0], 1, 350, 350)\n",
    "trainX = X_train.reshape(X_train.shape[0], 1, 350, 350)\n",
    "\n",
    "emotion_model.run_network([trainX, testX, Y_train, Y_test], model, batch=50, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"dwdii-emo-01v1.hdf5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References\n",
    "\n",
    "* OpenCV/CV2: http://askubuntu.com/questions/447409/how-to-install-opencv-2-9-for-python\n",
    "* Docker Commit: http://stackoverflow.com/questions/19585028/i-lose-my-data-when-the-container-exits\n",
    "  * docker ps -l\n",
    "  * docker commit <ContainerID> dittenhafer/dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
