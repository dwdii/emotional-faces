{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA622 Final Project\n",
    "Daniel Dittenhafer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook proceeds with using the trained convolutional neural network to predict emotion for each of the face images in the provided test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import emotion_model\n",
    "import dwdii_transforms\n",
    "\n",
    "random.seed(20275)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained on 150x150 images, therefore we will use this size of the test data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgDimension = []\n",
    "imgDimension.append(150)\n",
    "imgDimension.append(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Kaggle Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDataPath = \"../../facial_expressions/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "ls  = os.listdir(testDataPath)\n",
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000: y38.jpg\n",
      "0.076046: y06.jpg\n",
      "0.152091: BhanuPriya_60.jpg\n",
      "0.228137: NM.HA2.96.jpg\n",
      "0.304183: BomanIrani_9.jpg\n",
      "0.380228: 98a.jpg\n",
      "0.456274: KL.SA2.162.jpg\n",
      "0.532319: KL.DI2.171.jpg\n",
      "0.608365: 140a.jpg\n",
      "0.684411: Dileep_60.jpg\n",
      "0.760456: YM.AN2.62.jpg\n",
      "0.836502: KM.SU2.15.jpg\n",
      "0.912548: y28.jpg\n",
      "0.988593: y09.jpg\n"
     ]
    }
   ],
   "source": [
    "testData, fileList = dwdii_transforms.load_test_data(testDataPath, imgResize=imgDimension, verboseFreq=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 150, 150)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX = testData.reshape(testData.shape[0], 1, testData.shape[1],testData.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sadness': 6, 'neutral': 2, 'contempt': 7, 'disgust': 1, 'anger': 0, 'surprise': 4, 'fear': 5, 'happiness': 3}\n",
      "8\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_9 (Convolution2D)    (None, 32, 143, 143)2080        convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)         (None, 32, 143, 143)0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)      (None, 32, 71, 71)  0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D)   (None, 32, 67, 67)  25632       maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)         (None, 32, 67, 67)  0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)     (None, 32, 33, 33)  0           activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D)   (None, 64, 31, 31)  18496       maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)         (None, 64, 31, 31)  0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_11 (MaxPooling2D)     (None, 64, 15, 15)  0           activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D)   (None, 64, 14, 14)  16448       maxpooling2d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)         (None, 64, 14, 14)  0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_12 (MaxPooling2D)     (None, 64, 7, 7)    0           activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)                (None, 3136)        0           maxpooling2d_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                    (None, 64)          200768      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)         (None, 64)          0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                    (None, 8)           520         activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)         (None, 8)           0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 263944\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Map the emotions to integers for categorization later.\n",
    "emotions = dwdii_transforms.emotionNumerics()\n",
    "print emotions\n",
    "print len(emotions)\n",
    "\n",
    "model = emotion_model.emotion_model_jh_v5(len(emotions), verbose=True, \n",
    "                                        input_shape=(1,imgDimension[0],imgDimension[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadWeights = True\n",
    "if loadWeights:\n",
    "    #model.load_weights(\"dwdii-emo-150-jhv5a-Cloud.hdf5\")\n",
    "    model.load_weights(\"dwdii-emo-150-jhv5-9tf-Cloud.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 5s     \n"
     ]
    }
   ],
   "source": [
    "predictOutput = model.predict(testX, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many predictions?\n",
    "len(predictOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.88955162e-11   8.26386519e-18   9.99909699e-01   6.64880873e-10\n",
      "   6.71791713e-05   7.65165112e-14   2.31399081e-05   1.72253852e-20]\n"
     ]
    }
   ],
   "source": [
    "# Show an example of the prediction output\n",
    "print predictOutput[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(predictOutput[0]).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numEmo = dwdii_transforms.numericEmotions()\n",
    "numEmo[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y38.jpg'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist Predictions\n",
    "\n",
    "In this section we save the prediction results to a file in the prescribed Kaggle competition format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each prediction output, build the row for the CSV and add to our list for saving.\n",
    "outputData = []\n",
    "outputData.append([\"Image\", \"Emotion\"])\n",
    "for i in range(len(predictOutput)):\n",
    "    arPred = np.array(predictOutput[i])\n",
    "    predictionProb = arPred.max()\n",
    "    predictionNdx = arPred.argmax()\n",
    "    predictedEmo = numEmo[predictionNdx]\n",
    "    fileName = fileList[i]\n",
    "    outputData.append([fileName,predictedEmo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Image', 'Emotion'], ['y38.jpg', 'neutral'], ['KA.AN2.40.jpg', 'surprise'], ['KajalAgarwal_22.jpg', 'surprise'], ['FaridaJalal_149.jpg', 'happiness'], ['NA.HA2.203.jpg', 'surprise'], ['KM.FE2.24.jpg', 'surprise'], ['JayaBhaduri_42.jpg', 'neutral'], ['FaridaJalal_315.jpg', 'happiness'], ['186a.jpg', 'surprise']]\n"
     ]
    }
   ],
   "source": [
    "print outputData[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../output/dwdii_predictions.csv', 'w') as mycsvfile:\n",
    "    dw = csv.writer(mycsvfile)\n",
    "    for row in outputData:\n",
    "        dw.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Sanity Check Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "path = testDataPath + \"/JayaBhaduri_42.jpg\"\n",
    "img = misc.imread(path)\n",
    "img = misc.imresize(img, (150, 150))\n",
    "\n",
    "misc.imsave(\"test1000.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
