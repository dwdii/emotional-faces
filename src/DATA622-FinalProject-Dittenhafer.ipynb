{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA622 Final Project\n",
    "Daniel Dittenhafer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook proceeds with using the trained convolutional neural network to predict emotion for each of the face images in the provided test set as part of the [Emotion Detection Form Facial Expressions Kaggle competition](https://inclass.kaggle.com/c/emotion-detection-from-facial-expressions/leaderboard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import emotion_model\n",
    "import dwdii_transforms\n",
    "\n",
    "random.seed(20275)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained on 150x150 images, therefore we will use this size of the test data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgDimension = []\n",
    "imgDimension.append(150)\n",
    "imgDimension.append(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Kaggle Test Data\n",
    "\n",
    "In this section, the test data is loaded from the previously cloned facial_expressions GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDataPath = \"../../facial_expressions/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "ls  = os.listdir(testDataPath)\n",
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000: y38.jpg\n",
      "0.076046: y06.jpg\n",
      "0.152091: BhanuPriya_60.jpg\n",
      "0.228137: NM.HA2.96.jpg\n",
      "0.304183: BomanIrani_9.jpg\n",
      "0.380228: 98a.jpg\n",
      "0.456274: KL.SA2.162.jpg\n",
      "0.532319: KL.DI2.171.jpg\n",
      "0.608365: 140a.jpg\n",
      "0.684411: Dileep_60.jpg\n",
      "0.760456: YM.AN2.62.jpg\n",
      "0.836502: KM.SU2.15.jpg\n",
      "0.912548: y28.jpg\n",
      "0.988593: y09.jpg\n"
     ]
    }
   ],
   "source": [
    "testData, fileList = dwdii_transforms.load_test_data(testDataPath, imgResize=imgDimension, verboseFreq=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 150, 150)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX = testData.reshape(testData.shape[0], 1, testData.shape[1],testData.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sadness': 6, 'neutral': 2, 'contempt': 7, 'disgust': 1, 'anger': 0, 'surprise': 4, 'fear': 5, 'happiness': 3}\n",
      "8\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_17 (Convolution2D)   (None, 32, 143, 143)2080        convolution2d_input_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)         (None, 32, 143, 143)0           convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_17 (MaxPooling2D)     (None, 32, 71, 71)  0           activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D)   (None, 32, 67, 67)  25632       maxpooling2d_17[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)         (None, 32, 67, 67)  0           convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_18 (MaxPooling2D)     (None, 32, 33, 33)  0           activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D)   (None, 64, 31, 31)  18496       maxpooling2d_18[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)         (None, 64, 31, 31)  0           convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_19 (MaxPooling2D)     (None, 64, 15, 15)  0           activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D)   (None, 64, 14, 14)  16448       maxpooling2d_19[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)         (None, 64, 14, 14)  0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_20 (MaxPooling2D)     (None, 64, 7, 7)    0           activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)                (None, 3136)        0           maxpooling2d_20[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                    (None, 64)          200768      flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)         (None, 64)          0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                   (None, 8)           520         activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)         (None, 8)           0           dense_10[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 263944\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the emotion array for our count in the model definition\n",
    "emotions = dwdii_transforms.emotionNumerics()\n",
    "print emotions\n",
    "print len(emotions)\n",
    "# Construct the model using our help function\n",
    "model = emotion_model.emotion_model_jh_v5(len(emotions), verbose=True, \n",
    "                                        input_shape=(1,imgDimension[0],imgDimension[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadWeights = True\n",
    "if loadWeights:\n",
    "    #model.load_weights(\"dwdii-emo-150-jhv5a-Cloud.hdf5\")\n",
    "    #model.load_weights(\"dwdii-emo-150-jhv5-9tf-Cloud.hdf5\")\n",
    "    model.load_weights(\"dwdii-emo-150-jhv5-19tf-25e-Cloud.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 7s     \n"
     ]
    }
   ],
   "source": [
    "predictOutput = model.predict(testX, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many predictions?\n",
    "len(predictOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.42519587e-18   1.14439990e-25   9.99990165e-01   9.70902147e-06\n",
      "   7.69798614e-10   2.67830899e-22   1.11349941e-07   7.61658962e-22]\n"
     ]
    }
   ],
   "source": [
    "# Show an example of the prediction output\n",
    "print predictOutput[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(predictOutput[0]).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numEmo = dwdii_transforms.numericEmotions()\n",
    "numEmo[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y38.jpg'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist Predictions\n",
    "\n",
    "In this section we save the prediction results to a file in the prescribed Kaggle competition format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each prediction output, build the row for the CSV and add to our list for saving.\n",
    "outputData = []\n",
    "outputData.append([\"Image\", \"Emotion\"])\n",
    "for i in range(len(predictOutput)):\n",
    "    arPred = np.array(predictOutput[i])\n",
    "    predictionProb = arPred.max()\n",
    "    predictionNdx = arPred.argmax()\n",
    "    predictedEmo = numEmo[predictionNdx]\n",
    "    fileName = fileList[i]\n",
    "    outputData.append([fileName,predictedEmo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Image', 'Emotion'], ['y38.jpg', 'neutral'], ['KA.AN2.40.jpg', 'neutral'], ['KajalAgarwal_22.jpg', 'sadness'], ['FaridaJalal_149.jpg', 'neutral'], ['NA.HA2.203.jpg', 'neutral'], ['KM.FE2.24.jpg', 'happiness'], ['JayaBhaduri_42.jpg', 'neutral'], ['FaridaJalal_315.jpg', 'happiness'], ['186a.jpg', 'sadness']]\n"
     ]
    }
   ],
   "source": [
    "print outputData[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../output/dwdii_predictions-19tf-25e.csv', 'w') as mycsvfile:\n",
    "    dw = csv.writer(mycsvfile)\n",
    "    for row in outputData:\n",
    "        dw.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Sanity Check Code\n",
    "\n",
    "I wanted to make sure the resizing didn't cause significant distortion for images which werent' square already. The following code helped with this sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "path = testDataPath + \"/JayaBhaduri_42.jpg\"\n",
    "img = misc.imread(path)\n",
    "img = misc.imresize(img, (150, 150))\n",
    "\n",
    "misc.imsave(\"test1000.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
